#!/usr/bin/env python

import os, sys
join = os.path.join
from glob import glob
from DVCode.Tools.CRAB3ToolsBase import crabify_list, crab_jobs_from_argv
from DVCode.Tools.CondorSubmitter import CondorSubmitter
from DVCode.Tools.CondorTools import *
from DVCode.Tools.general import mkdirp

if len(sys.argv) < 3:
    print 'usage: cs_resubmit condor_dir jobs_list'
    print '    jobs_list can be space separated, or can handle a string like 1,3,5-7'
    sys.exit(1)

wd = os.path.abspath(sys.argv[1])
if not is_cs_dir(wd):
    raise ValueError('first arg must be a CondorSubmitter dir')

jobs = crab_jobs_from_argv()
if not jobs:
    raise ValueError('expect a list of jobs in argv')

print wd, 'resubmit jobs', crabify_list(jobs)

norigjobs = cs_njobs(wd)
running_jobs = cs_jobs_running(wd)

for job in jobs:
    if job >= norigjobs:
        raise ValueError('supplied job number %i >= norigjobs %i' % (job, norigjobs))
    if job in running_jobs:
        raise RuntimeError('refuse to resubmit job %i, still running (maybe held?)' % job)
    #if not all(os.path.isfile(join(wd, '%s.%i' % (x,job))) for x in ('log', 'stdout', 'stderr')):
    #    raise RuntimeError("was job %i ever run? one of stdout, stderr, log file doesn't exist for it" % job)

i, rd = 1, None
while 1:
    rd = join(wd, 'resub' + str(i))
    if not os.path.exists(rd):
        break
    i += 1
    if i == 20:
        raise RuntimeError('way too many resubmissions')
os.mkdir(rd)
brd = os.path.basename(rd)
def rd_f(fn):
    return open(join(rd, fn), 'wt')
    
rd_f('cs_jobmap').write('\n'.join(str(i) for i in jobs) + '\n')

jdl = open(join(wd, 'cs_submit.jdl')).readlines()
assert jdl[-1].startswith('Queue ')
jdl[-1] = 'Queue %i\n' % len(jobs)
rd_f('cs_submit.jdl').write(''.join(jdl))

# run.sh in this list bc some jobs (combine) make a run.sh per batch dir, otherwise this is handled with an abspath in the jdl generated by CondorSubmitter
for bn in ('cs.json', 'cs_filelist.py', 'cs_cmsrun_args', 'cs_primaryds', 'cs_samplename', 'cs_pset.py', 'cs_njobs', 'run.sh'):
    wn = join(wd, bn)
    if os.path.isfile(wn):
        os.symlink(wn, join(rd, bn))

rd_f('cs_timestamp').write(cs_timestamp())

orig_d = join(wd, 'originals')
mkdirp(orig_d)

def had(x):
    x = join(wd,x)
    return os.path.isfile(x) and os.stat(x).st_size > 0
had_outputfiles   = had('cs_outputfiles')
had_stageoutfiles = had('cs_stageoutfiles')

output_bns = [('fjr', '.xml')]
if had_stageoutfiles:
    output_bns.append(('publish', '.txt'))
if had_outputfiles:
    output_bns += [os.path.splitext(bn) for bn in open(join(wd, 'cs_outputfiles')).read().split()]

for ijob, job in enumerate(jobs):
    djob = '.%i' % job
    ujob = '_%i' % job
    condor_fns = [join(wd, x + djob) for x in ('log', 'stderr', 'stdout')]
    output_fns = [join(wd, b + ujob + ext) for b, ext in output_bns]

    for fn in condor_fns + output_fns:
        bn = os.path.basename(fn)

        if os.path.islink(fn): # don't keep track of previously resubmitted job files
            os.remove(fn)
        elif os.path.isfile(fn):
            os.rename(fn, join(orig_d, bn))
        elif os.path.exists(fn):
            raise IOError('wtf %s' % fn)

        if fn in condor_fns:
            target = join(brd, bn.replace(djob, '.%i' % ijob))
        elif fn in output_fns:
            target = join(brd, bn)
        os.symlink(target, fn)

if 'testing' not in sys.argv:
    CondorSubmitter._submit(rd, len(jobs))
