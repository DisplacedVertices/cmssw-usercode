#!/usr/bin/env python

import datetime, optparse, os, sys, time, shutil
from collections import defaultdict
from CRABClient.ClientExceptions import ConfigurationException as CRABConfigurationException
from JMTucker.Tools.CRAB3Tools import *
from JMTucker.Tools.CondorTools import *
from JMTucker.Tools.general import print_if_nonempty, touch
from JMTucker.Tools import colors

parser = optparse.OptionParser(usage='%prog [options] <space-separated list of crab dirs>')
parser.add_option('-v', '--verbose', action='store_true', default=False,
                  help='Print way more.')
parser.add_option('-c', '--continuous', action='store_true', default=False,
                  help='Keep making passes.')
parser.add_option('-w', '--wait-time', type='int', default=-1,
                  help='Time between passes, in seconds. Default is %default.')
parser.add_option('-d', '--delay', action='store_true', default=False,
                  help='Wait once before starting passes.')
parser.add_option('--max-processes', type='int', default=5,
                  help='Max number of status-checking processes to run at once.')
parser.add_option('--override-done', action='store_true', default=False,
                  help='Ignore already-done marker files.')
parser.add_option('-r', '--resub', action='store_true', default=False,
                  help='Send resubmit request to any batch that has failed jobs, obeying the white and black lists below. (Only crab dirs for now.)')
parser.add_option('--resub-force', action='store_true', default=False,
                  help='Use the --force option on resubmit (implies --resub).')
parser.add_option('--resub-xferring', action='store_true', default=False,
                  help='Resubmit jobs that claim to be xferring (implies --resub-force and --resub).')
parser.add_option('--resub-condor', action='store_true', default=False,
                  help='Resubmit condor jobs with "probs" or "killed" (implies --resub).')
#parser.add_option('--resub-white-list', default='',
#                  help='Comma-separated list (no spaces!) of sites to whitelist when resubmitting.')
#parser.add_option('--resub-black-list', default='',
#                  help='Comma-separated list (no spaces!) of sites to blacklist when resubmitting.')
#parser.add_option('--resub-white-codes', default='',
#                  help='Comma-separated list (no spaces!) of codes that are allowed to resubmit -- all others not resubmitted.')
#parser.add_option('--resub-black-codes', default='',
#                  help='Comma-separated list (no spaces!) of codes that are not allowed to resubmit -- all others are resubmitted.')
parser.add_option('--fake-results', type='str', metavar='FILE',
                  help='Read fake results dict from FILE.')
parser.add_option('--no-dir-sort', action='store_false', dest='dir_sort', default=True,
                  help='Do not resort the list of directories.')
parser.add_option('-n', '--no-renew-proxies', action='store_false', dest='renew_proxies', default=True,
                  help='Do not renew proxies first.')
parser.add_option('--no-shorten-statuses', action='store_false', dest='shorten_statuses', default=True,
                  help='Do not shorten statuses in the status table.')
parser.add_option('-a', '--hadd', action='store_true', default=False,
                  help='At the end of each iteration, hadd the done dirs. The destination path for the output file is next to the dir.')
parser.add_option('-b', '--hadd-rm', action='store_true', default=False,
                  help='Like --hadd, but remove the originals (passes -r to mhadd).')
parser.add_option('-p', '--publicweb', action='store_true', default=False,
                  help='Write results of continuous mmon to publicweb area (if it is set up properly!)')
options, args = parser.parse_args()
#print options ; print args ; import sys ; print sys.argv ; raise 1

################################################################################

def print_header(s):
    print '\033[1m%s\033[0m' % s
def print_subheader(s):
    print '\033[32m%s\033[0m' % s

#if options.resub_white_list and options.resub_black_list:
#    raise ValueError('cannot have both --resub-white-list and --resub-black-list')
#
#if options.resub_white_codes and options.resub_black_codes:
#    raise ValueError('cannot have both --resub-white-codes and --resub-black-codes')
#
#options.resub_white_codes = options.resub_white_codes.split(',')
#options.resub_black_codes = options.resub_black_codes.split(',')

if options.resub_xferring and not options.resub_force:
    print '--resub-xferring implies --resub-force, setting it.'
    options.resub_force = True

if options.resub_force:
    if not options.resub:
        print '--resub-force implies resub, setting it.'
        options.resub = True
    if options.continuous:
        print 'refusing to force resubmits in continuous mode, only running once'
        options.continuous = False

if options.resub_condor and not options.resub:
    options.resub = True

if options.continuous and options.fake_results:
    print '--fake-results implies not continuous, setting it.'
    options.continuous = False

if options.wait_time > 0 or options.delay:
    options.continuous = True
if options.continuous and options.wait_time < 0:
    options.wait_time = 60*10

if options.hadd_rm:
    options.hadd = True

def timestamp():
    return str(int(time.time()*1e6))

backdoor_time = timestamp()
uname = os.environ['USER']

def backdoor_file(filename):
    fn = '/tmp/%s/mmon_%s_%s' % (uname, backdoor_time, filename)
    return fn, open(fn, 'wt')

def backdoor_print(filename, l):
    ll = []
    for a in l:
        if a.endswith('\\'):
            a = a.rsplit('\\')[0]
        ll.append(a)
    s = '\n'.join(ll) + '\n'
    fn, f = backdoor_file(filename)
    f.write(s)
    print filename, 'is', fn
    print s
    return s

def make_script(filename, cmd):
    fn, f = backdoor_file(filename)
    f.write(cmd)
    return fn

def copy_log_file(tmp_logfile_path, publicweb_logfile_path, uname) :
    try :
        shutil.copy(tmp_logfile_path, publicweb_logfile_path)
    except IOError :
        # likely the Kerberos ticket is gone, so do a kinit via keytabs, set up with:
        # https://stackoverflow.com/questions/8144596/kerberos-kinit-enter-password-without-prompt/55826172#55826172
        print "IOError in shutil.copy, retrying with new kerberos ticket"
        os.system("kinit -kt /uscms/home/%s/.keytabs/%s.keytab %s@FNAL.GOV" % (uname, uname, uname) )
        shutil.copy(tmp_logfile_path, publicweb_logfile_path)
    return

dirs = crab_dirs_from_argv() + cs_dirs_from_argv()

dirs_done = []
done_fn = lambda d: os.path.join(d, 'mmon_done')
has_done_marker = lambda d: os.path.isfile(done_fn(d))

if not options.override_done:
    dirs_done = [d for d in dirs if has_done_marker(d)]
    dirs      = [d for d in dirs if not has_done_marker(d)]
    if dirs_done and not dirs:
        sys.exit('no dirs left!')

if not dirs and not options.fake_results:
    sys.exit('space-separated list of existing crab or condor dirs required in argv (see --help)')

if options.dir_sort:
    dirs.sort()

ndirs = len(dirs)
nskipped = len(dirs_done)
print 'mmon: checking %i dir%s%s, be patient' % (ndirs,
                                                 's' if ndirs > 1 else '',
                                                 ' (%i skipped)' % nskipped if nskipped else '')

def check_proxies():
    if options.renew_proxies:
        crab_renew_proxy_if_needed()

check_proxies()

if options.delay:
    print 'delay requested: sleeping %i seconds before doing anything' % options.wait_time
    time.sleep(options.wait_time)

to_resub_done = {}

pass_count = 0
pass_string = ''
last_proxy_check = time.time()

while 1:
    the_time = time.time()
    if (the_time - last_proxy_check)/3600. > 8:
        check_proxies()
        last_proxy_check = the_time

    pass_string = str(int(time.time()))

    # logfile in tmp area, to be copied to publicweb after each iteration
    if options.publicweb :
        publicweb_logfile_path = "/publicweb/%s/%s/" % (uname[0], uname)
        tmp_logfile_path = "/tmp/%s/mmon_log.txt" % uname
        os.system('mkdir -p /tmp/%s' % uname)
        logfile = open(tmp_logfile_path,"w")

    if options.continuous:
        print '\n*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\nmaking a pass (#%i string %s):\n' % (pass_count, pass_string)

    if options.fake_results:
        # Fake statuses for debugging the table printing below.
        print 'fake_results dict:'
        results = open(options.fake_results).read().strip()
        pprint(results)
        results = eval(results)
        dirs = sorted(results.keys())
    else:
        # Get the statuses of all the dirs. 
        results = {}
        crab_dirs = [d for d in dirs if is_crab_working_dir(d)]
        condor_dirs = [d for d in dirs if is_cs_dir(d)]
        if crab_dirs:
            results.update(crab_process_statuses_with_redo(crab_dirs, options.max_processes))
            crab_cleanup()
        if condor_dirs:
            results.update(cs_analyze_mmon(condor_dirs))

        os.system('mkdir -p /tmp/%s' % uname)
        open('/tmp/%s/mmontmp' % uname, 'wt').write(repr(results))
        #pprint(results)

        # get last status from our special file and save this one
        last_status_fn = lambda d: os.path.join(d, 'mmon_last')
        for d,res in results.iteritems():
            fn = last_status_fn(d)
            r_this = repr(res)
            if os.path.isfile(fn):
                res['last'] = eval(open(fn).read())
            else:
                res['last'] = None
            open(fn, 'wt').write(r_this)

        # Resubmit those allowed.
        if options.resub:
            to_resub = defaultdict(list)
            for d, res in results.iteritems():
                if is_crab_working_dir(d):
                    to_resub[d].extend(res['jobListByStatus'].get('failed', []))
                    if options.resub_xferring:
                        to_resub[d].extend(res['jobListByStatus'].get('transferring', []))
                elif is_cs_dir(d) and options.resub_condor:
                    to_resub[d].extend(res['jobListByStatus'].get('probs', []))
                    to_resub[d].extend(res['jobListByStatus'].get('killed', []))
# 'Error' not present in job json since 5/14/2017
#               for something in something else:
#                    job = res['jobs'][str(job_num)]
#                    err_code = job['Error'][0]
#                    if any((not options.resub_white_list and not options.resub_black_list,
#                            options.resub_white_list and err_code in options.resub_white_list,
#                            options.resub_black_list and err_code not in options.resub_black_list)):
#                        to_resub[d].append(job_num)
            for d, jobs in to_resub.iteritems():
                if jobs:
                    jobs = ','.join(str(j) for j in jobs)
                    print 'resubmit', d, jobs
                    if is_crab_working_dir(d):
                        try:
                           #crab_command('resubmit', dir=d, jobids=jobs, sitewhitelist=options.resub_white_list, siteblacklist=options.resub_black_list, suppress_stdout=False)
                            crab_command('resubmit', dir=d, jobids=jobs, force=options.resub_force) #, suppress_stdout=False)
                        except CRABConfigurationException:
                            print 'CRABConfigurationException when resubmitting, skip this time'
                    elif is_cs_dir(d):
                        os.system('cs_resubmit %s %s' % (d, jobs))

    if options.verbose:
        # Print a recap of all the status summaries.
        print
        print_header('Recap (everything, sorted by directory):')
        for d in dirs:
            if not results.has_key(d):
                continue
            print_subheader('%s:' % d)
            job_lists = results[d]['jobListByStatus']
            for status in sorted(job_lists.keys()):
                print '%s: %s' % (status.ljust(25), crabify_list(job_lists[status], simple=False))

        print
        print_header('Recap (everything, sorted by status):')
        statuses = defaultdict(list)
        for d in dirs:
            job_lists = results[d]['jobListByStatus']
            for status in job_lists.keys():
                statuses[status].append(d)
        for status in sorted(statuses.keys()):
            print_subheader('%s:' % status)
            these_dirs = [d for d in statuses[status] if d in dirs]
            these_dirs.sort()
            max_w = max(len(d) for d in these_dirs)
            for d in these_dirs:
                job_lists = results[d]['jobListByStatus']
                print '%s %s' % (d.ljust(max_w + 1), crabify_list(job_lists[status], simple=False))

    #print
    #print_header('Recap (skipping exit code 0 but  where X, Y != 0):')
    to_resub = defaultdict(list)
    to_resub.update(to_resub_done)

    # Now print a big summary table where the rows are directories and
    # the columns are the statuses, with the entries being the number
    # of jobs in the directory for each status.

    # Figure out the header row for the status columns. Alphabetical
    # by status, except put finished first. We'll also shorten
    # the status codes, either displaying the short ones all the time,
    # or perhaps only doing it when the table would be wider than the
    # current terminal (not implemented yet).
    status_columns = sorted(set(sum((res['jobsPerStatusEx'].keys() for res in results.itervalues()), [])))
    if 'finished' in status_columns:
        status_columns.remove('finished')
        status_columns = ['finished'] + status_columns

    status_columns_short = []
    status_columns_xlate = {}
    to_replace = [
        ('finished', 'fin'),
        ('failed', 'fail'),
        ('running', 'run'),
        ('trans', 'x'),
        ]

    if options.shorten_statuses:
        for status in status_columns:
            status_short = status
            for a,b in to_replace:
                status_short = status_short.replace(a,b)

            status_columns_short.append(status_short)
            status_columns_xlate[status_short] = status

        status_columns = status_columns_short

    status_column_format = ''.join('%' + str(max(len(status_column) + 2, 6)) + 's' for status_column in status_columns)

    # The table format string: a left-justified column for the
    # directory names, then a column showing whether the
    # output has changed, then followed by columns for all of the statuses
    # seen, with the width found above.
    dir_column_width = max(len(d) for d in results.keys())
    table_format = '%-' + str(dir_column_width) + 's'
    table_format += '%3s' # for the stale-status column
    table_format += '%8s' # for the totals column
    table_format += status_column_format
    #print repr(table_format)

    # Header.
    header = ['directory', 'S?', 'total |'] + status_columns
    print_header(table_format % tuple(header))
    if options.publicweb :
        logfile.write(table_format % tuple(header)+"\n")

    class StatusCounter:
        def __init__(self, statuses):
            self.nfail, self.nrun, self.nfin = -1, -1, -1
            if statuses:
                self.nfail, self.nrun, self.nfin = 0, 0, 0
                for status, entry in statuses.iteritems():
                    if status.startswith('fin'):
                        self.nfin += entry
                    elif status.startswith('fail') or status.startswith('kill') or status.startswith('prob'):
                        self.nfail += entry
                    else:
                        self.nrun += entry

    # Print out all the rows. Column order is as above.
    sums = (len(status_columns)+1)*[0]
    for d in dirs:
        statuses = results[d]['jobsPerStatusEx']
        row = []
        for status in status_columns:
            entry = statuses.get(status_columns_xlate.get(status, status), 0)
            row.append((status, entry))
        sub_row = tuple(x[1] for x in row)
        row_total = sum(sub_row)
        sums[0] += row_total
        for i, x in enumerate(sub_row):
            sums[i+1] += x
        sub_row = tuple('-' if x == 0 else x for x in sub_row) # suppress zeroes to make table easier to read

        counts = StatusCounter(statuses)
        stale = 'X'
        if results[d].get('last', None) is not None:
            counts_last = StatusCounter(results[d]['last']['jobsPerStatusEx'])
            if counts.nfin != counts_last.nfin:
                stale = ' '
            else:
                stale = '!'

        row = (d, stale, '%s |' % row_total) + sub_row

        if counts.nfin == row_total:
            color = colors.green
        elif counts.nfail:
            color = colors.magenta
        elif counts.nrun:
            color = colors.cyan

        print color(table_format % row)
        if options.publicweb :
            logfile.write(table_format % row + "\n")

    sums[0] = '%s |' % sums[0]
    sums = tuple(['totals', ''] + sums)
    sum_row = table_format % sums
    print colors.bold(sum_row)
    print

    if options.publicweb :
        logfile.write(sum_row + "\n")

    # Figure out which directories are done, and remove them from the
    # list of dirs to check next time. Also print out a new mmon
    # command for pasting that just resubmits dirs that are able.

    done_stats = set(''.split())
    done_stats_info_text = repr(tuple(sorted(done_stats)))
    fail = []
    done = []
    notdone = []
    for k,v in results.iteritems():
        if any(stat for stat in v['jobsPerStatusEx'].keys() if 'fail' in stat):
            fail.append(k)
        statuses_left = set(stat for stat in v['jobsPerStatusEx'].keys() if stat != 'finished')
        statuses_left -= done_stats
        (notdone if statuses_left else done).append(k)
    fail.sort(key=dirs.index)
    done.sort(key=dirs.index)
    notdone.sort(key=dirs.index)

    for d in done:
        touch(done_fn(d))

    if options.hadd:
        for d in done:
            cmd = 'mhadd %s -o %s' % (d, os.path.dirname(d))
            if options.hadd_rm:
                cmd = cmd.replace('mhadd', 'mhadd -r')
            print cmd
            os.system(cmd)

    done_msg = '\nThese are done as far as mmon is concerned (all jobs are "finished" or one of %s):' % done_stats_info_text 
    if done:
        if options.verbose:
            print_header(done_msg)
            for d in done:
                print d
            print_header('These are not:')
            for d in notdone:
                print d
            print_header('Stopping monitoring of the former.')
        for d in done:
            if to_resub.has_key(d):
                to_resub_done[d] = to_resub[d]
            dirs.remove(d)
            d_statuses = results[d]['jobsPerStatusEx'].keys()
            if len(d_statuses) != 1 or d_statuses[0] != 'finished':
                dirs_done.append((d,) + tuple(d_statuses))
            else:
                dirs_done.append(d)

    if options.verbose and dirs_done:
        print_header(done_msg)
        for d in dirs_done:
            print d

    if fail:
        print colors.bold('Resubmit failed:')
        print '.', make_script('resubmit', 'cr res ' + ' '.join(fail))

    if not dirs:
        print_header('All done!')
        if options.publicweb :
            logfile.write('All done!')
            logfile.close()
            copy_log_file(tmp_logfile_path, publicweb_logfile_path, uname)
        break

    if not options.continuous:
        break

    # Might want to break but can't count on being in front of the
    # terminal when a very long iteration finishes. Look for a special
    # file in /tmp/$USER that signals we should break.

    break_fn =  '/tmp/%s/break_mmon' % uname
    if os.path.isfile(break_fn):
        os.remove(break_fn)
        print_header('break file spotted, quitting.')
        break
    
    # Sleep for the specified time.
    
    now = datetime.datetime.now()
    then = now + datetime.timedelta(seconds=options.wait_time)
    print colors.bold('That was pass #%i string %s. Going to sleep for %i seconds at %s. Will wake up at %s.' % (pass_count, pass_string, options.wait_time, now, then))
    print '(Hit Ctrl-C, then enter to immediately start the next iteration. Or, hit Ctrl-C, then Ctrl-C to quit.)'

    if options.publicweb :
        logfile.write('That was pass #%i string %s. Going to sleep for %i seconds at %s. Will wake up at %s.' % (pass_count, pass_string, options.wait_time, now, then))
        logfile.close()
        copy_log_file(tmp_logfile_path, publicweb_logfile_path, uname)

    pass_count += 1

    try:
        time.sleep(options.wait_time)
    except KeyboardInterrupt:
        raw_input('quit?')
