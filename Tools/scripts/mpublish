#!/usr/bin/env python

import os, sys, argparse
from fnmatch import fnmatch
from pprint import pprint
from JMTucker.Tools.CRAB3ToolsBase import crab_dirs_from_argv
from JMTucker.Tools.CRAB3ToolsSh import crab_get_njobs_from_log, crab_get_output_dataset_from_log, crab_get_output_dir
from JMTucker.Tools.CondorTools import cs_dirs_from_argv, cs_njobs, cs_primaryds, cs_eventswritten
from JMTucker.Tools.DBS import files_in_dataset, numevents_in_dataset
from JMTucker.Tools.general import coderep_files, popen
from JMTucker.Tools import Samples, colors
from JMTucker.Tools.SampleFiles import _enc

parser = argparse.ArgumentParser(description = 'mpublish: get the staged-out files from condor/crab directories and print out lines for SampleFiles.py',
                                 usage = '%(prog)s [options] condor_or_crab_dirs')

parser.add_argument('condor_or_crab_dirs', nargs='*', help='The condor/crab directories.')

parser.add_argument('--dataset', default='ChangeMe',
                    help='The dataset name to use.')
parser.add_argument('--blacklist', nargs='*', default=['vertex_histos*root'],
                    help="Don't include files that match these patterns (default %(default)s).")
parser.add_argument('--pattern',
                    help='Glob-style pattern to filter the files, useful if there are multiple files output per job.')
parser.add_argument('--partial', action='store_true',
                    help='If set, partial publishing is allowed.')
parser.add_argument('--only-done', action='store_true',
                    help='If set, only look at dirs with the mmon_done marker file.')
parser.add_argument('--no-coderep', action='store_false', dest='coderep', help='whether to disable coderep output')
parser.add_argument('--no-lpc-shortcut', action='store_false', dest='lpc_shortcut', help='whether to use the lpc shortcut on crab dirs')
parser.add_argument('--no-dbs', action='store_false', dest='dbs', help='whether to use information from dbs')
parser.add_argument('--nevents-per-job', type=int, default=-1, help='nevents to use if reading dbs fails')
parser.add_argument('--include-condor-nevents', action='store_true',
                    help='If set, parse xmls to get nevents from condor wds.')
parser.add_argument('--from-merge', action='store_true', help='Input is from merge jobs (implies --partial and --no-coderep).')

options = parser.parse_args()
if options.from_merge:
    options.partial = True
    options.coderep = False

# as far as I know, it should be fine to always use lowercase for these,
# and can be a problem when it's not...
options.dataset = options.dataset.lower()

########################################################################

wds = cs_dirs_from_argv() + crab_dirs_from_argv()
if not wds:
    print 'No dirs in argv\n'
    parser.print_help()
    sys.exit(1)

def fn_ok(fn):
    if not fn.endswith('.root'):
        return False
    bn = os.path.basename(fn)
    if options.pattern and not fnmatch(bn, options.pattern):
        return False
    for bl in options.blacklist:
        if fnmatch(bn, bl):
            return False
    return True

def extract_sample(wd):
    bd = os.path.basename(wd)
    is_crab = bd.startswith('crab_')
    assert is_crab or bd.startswith('condor_')
    first_str = 'crab_' if is_crab else 'condor_'
    if options.dataset == 'main':
        sample = os.path.basename(wd).replace(first_str, '')
    else:
        try:
            sample = Samples.sample_from_end_string(Samples, wd).name
        except AttributeError:
            raise ValueError('cannot find sample name from %s, rerun with --main?' % wd)
    return is_crab, sample

publish = {}
samples = []
samples_lump = []
not_done_skipped = []
for wd in wds:
    print colors.bold(wd)
    is_crab, sample = extract_sample(wd)

    if options.only_done:
        if not os.path.isfile(os.path.join(wd, 'mmon_done')):
            not_done_skipped.append(sample)
            print colors.yellow('not done, skipping')
            continue

    if publish.has_key(sample):
        raise ValueError('sample %s already encountered' % sample)

    if is_crab:
        njobs = crab_get_njobs_from_log(wd)

        ds = crab_get_output_dataset_from_log(wd)
        if ds is None and not options.partial:
            raise ValueError('no dataset in log for ' + wd)
        dbs_files = []
        nevents = -1
        if options.dbs:
            try:
                dbs_files = files_in_dataset(ds, 3)
                nevents = numevents_in_dataset(ds, 3)
            except RuntimeError:
                print colors.yellow('problem with dbs for %s, len(dbs_files) = %i and nevents is %r' % (ds, len(dbs_files), nevents))
        files = []
        if options.lpc_shortcut:
            path = crab_get_output_dir(wd)
            zero_dirs = [x.strip() for x in popen('eos root://cmseos.fnal.gov ls /eos/uscms%s' % path).split('\n') if x.strip()]
            for zd in zero_dirs:
                d = os.path.join(path, zd) + '/'
                files += [d + x.strip() for x in popen('eos root://cmseos.fnal.gov ls /eos/uscms%s/%s' % (path, zd)).split() if x.strip() and fn_ok(x.strip())]

            if options.dbs and set(files) != set(dbs_files):
                msg = '%i files from lpc shortcut != %i files from dbs' % (len(files), len(dbs_files))
                if options.partial:
                    print colors.yellow(msg)
                else:
                    raise ValueError(msg)
        else:
            assert options.dbs
            files = dbs_files
        if nevents == -1 and options.nevents_per_job > 0:
            nevents = len(files) * options.nevents_per_job
    else:
        njobs = cs_njobs(wd)
        ds = '/%s/None/None' % cs_primaryds(wd)
        files = []
        for job in xrange(njobs):
            publish_fn = os.path.join(wd, 'publish_%i.txt' % job)
            if not os.path.isfile(publish_fn):
                if options.partial:
                    print colors.yellow('warning: missing %s' % publish_fn)
                else:
                    raise IOError('no publish file %s' % publish_fn)
            else:
                for fn in open(publish_fn):
                    files.append(fn.strip()[fn.find('/store'):])
        nevents = cs_eventswritten(wd) if options.include_condor_nevents else 0

    files = [str(fn) for fn in files if fn_ok(fn)]
    if not files:
        msg = 'warning: no files found for %s' % wd
        if options.partial:
            print colors.yellow(msg)
            continue
        else:
            raise ValueError(msg)

    if len(files) != njobs:
        msg = '# files %i != njobs %i' % (len(files), njobs)
        if options.partial:
            print colors.yellow('warning: %s, but partial publish allowed' % msg)
        else:
            raise ValueError(msg)

    if not ds or (ds.endswith('/None') and nevents == 0):
        samples_lump.append(sample)
    else:
        samples.append((sample, ds, nevents))
    code = coderep_files(files) if options.coderep else None
    publish[sample] = (len(files), code if code is not None else files)

def _key(x):
    if type(x) == tuple:
        sample_name, _, _ = x
    else:
        assert type(x) == str
        sample_name = x
    if hasattr(Samples, sample_name):
        return getattr(Samples, sample_name).isample
    else:
        return -1

samples.sort(key=_key)
samples_lump.sort(key=_key)

print
print colors.bold('new entries:')
print '_add_ds("%s", {' % options.dataset
for k in sorted(publish.keys(), key=_key):
    n,c = publish[k]
    if type(c) == unicode:
        c = str(c)
    if type(c) == str:
        if '_fromnum' in c:
            if int(c.replace(')', '').split(',')[1]) != n:
                print 'OOPS', n
            print '%r: %s,' % (k, c)
        else:
            print '%r: (%i, %s),' % (k, n, c)
    else:
        print "'%s': (%i, %r)," % (k, n, c)
print '})'
print
encoded = _enc(publish)
print colors.bold('line for SampleFiles (len(repr(publish)) = %i, len(encoded) = %i):' % (len(repr(publish)), len(encoded)))
print "_add('%s')" % encoded
print
print colors.bold('lines for Samples:')
for sample, ds, nevents in samples:
    print "%s.add_dataset('%s', '%s', %i)" % (sample, options.dataset, ds, nevents)
if samples_lump:
    print 'for x in %s:' % ', '.join(samples_lump)
    print '    x.add_dataset("%s")' % options.dataset
if not_done_skipped:
    print 'or use lists with:\n    if x in (%s):\n        continue' % ', '.join(not_done_skipped)
